{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Dimension Reduction\n",
    "Execute the below code and answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.922486</td>\n",
       "      <td>1.047879</td>\n",
       "      <td>-2.963721</td>\n",
       "      <td>-0.056906</td>\n",
       "      <td>1.265347</td>\n",
       "      <td>3.858544</td>\n",
       "      <td>0.491978</td>\n",
       "      <td>-0.490947</td>\n",
       "      <td>-4.320868</td>\n",
       "      <td>0.593099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536582</td>\n",
       "      <td>-0.725250</td>\n",
       "      <td>1.331478</td>\n",
       "      <td>1.185142</td>\n",
       "      <td>-2.963721</td>\n",
       "      <td>1.314720</td>\n",
       "      <td>2.487634</td>\n",
       "      <td>-0.424585</td>\n",
       "      <td>0.995500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.210683</td>\n",
       "      <td>-2.384247</td>\n",
       "      <td>2.590403</td>\n",
       "      <td>-2.600047</td>\n",
       "      <td>-1.039447</td>\n",
       "      <td>-0.687409</td>\n",
       "      <td>0.847554</td>\n",
       "      <td>-0.563711</td>\n",
       "      <td>-4.944035</td>\n",
       "      <td>0.357768</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.811372</td>\n",
       "      <td>-1.981515</td>\n",
       "      <td>0.212563</td>\n",
       "      <td>1.569957</td>\n",
       "      <td>2.590403</td>\n",
       "      <td>2.475946</td>\n",
       "      <td>0.866024</td>\n",
       "      <td>1.414244</td>\n",
       "      <td>0.337811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.428323</td>\n",
       "      <td>-4.476885</td>\n",
       "      <td>8.180427</td>\n",
       "      <td>-4.260930</td>\n",
       "      <td>-1.435362</td>\n",
       "      <td>-6.440634</td>\n",
       "      <td>4.620321</td>\n",
       "      <td>-1.400001</td>\n",
       "      <td>-7.511350</td>\n",
       "      <td>1.946596</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.506842</td>\n",
       "      <td>0.704681</td>\n",
       "      <td>-2.628639</td>\n",
       "      <td>3.458000</td>\n",
       "      <td>8.180427</td>\n",
       "      <td>3.718988</td>\n",
       "      <td>0.771003</td>\n",
       "      <td>-1.153540</td>\n",
       "      <td>-0.148205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.631406</td>\n",
       "      <td>0.255251</td>\n",
       "      <td>-4.260573</td>\n",
       "      <td>1.140672</td>\n",
       "      <td>-0.738570</td>\n",
       "      <td>5.966119</td>\n",
       "      <td>-5.335446</td>\n",
       "      <td>-0.729138</td>\n",
       "      <td>5.655376</td>\n",
       "      <td>-0.852272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733406</td>\n",
       "      <td>1.295768</td>\n",
       "      <td>-1.049316</td>\n",
       "      <td>3.925402</td>\n",
       "      <td>-4.260573</td>\n",
       "      <td>-4.457084</td>\n",
       "      <td>-2.563916</td>\n",
       "      <td>-1.388560</td>\n",
       "      <td>0.179481</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.217200</td>\n",
       "      <td>-3.333409</td>\n",
       "      <td>4.420645</td>\n",
       "      <td>1.231249</td>\n",
       "      <td>-0.081330</td>\n",
       "      <td>-2.874278</td>\n",
       "      <td>1.404699</td>\n",
       "      <td>0.680510</td>\n",
       "      <td>4.243968</td>\n",
       "      <td>2.281619</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104220</td>\n",
       "      <td>1.120948</td>\n",
       "      <td>-1.349871</td>\n",
       "      <td>-1.680847</td>\n",
       "      <td>4.420645</td>\n",
       "      <td>-3.035590</td>\n",
       "      <td>-1.190401</td>\n",
       "      <td>-0.421525</td>\n",
       "      <td>-0.883157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0  0.922486  1.047879 -2.963721 -0.056906  1.265347  3.858544  0.491978   \n",
       "1  1.210683 -2.384247  2.590403 -2.600047 -1.039447 -0.687409  0.847554   \n",
       "2  0.428323 -4.476885  8.180427 -4.260930 -1.435362 -6.440634  4.620321   \n",
       "3 -0.631406  0.255251 -4.260573  1.140672 -0.738570  5.966119 -5.335446   \n",
       "4 -1.217200 -3.333409  4.420645  1.231249 -0.081330 -2.874278  1.404699   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0 -0.490947 -4.320868  0.593099  ...  0.536582 -0.725250  1.331478  1.185142   \n",
       "1 -0.563711 -4.944035  0.357768  ... -1.811372 -1.981515  0.212563  1.569957   \n",
       "2 -1.400001 -7.511350  1.946596  ... -2.506842  0.704681 -2.628639  3.458000   \n",
       "3 -0.729138  5.655376 -0.852272  ... -0.733406  1.295768 -1.049316  3.925402   \n",
       "4  0.680510  4.243968  2.281619  ...  2.104220  1.120948 -1.349871 -1.680847   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -2.963721  1.314720  2.487634 -0.424585  0.995500     1.0  \n",
       "1  2.590403  2.475946  0.866024  1.414244  0.337811     0.0  \n",
       "2  8.180427  3.718988  0.771003 -1.153540 -0.148205     0.0  \n",
       "3 -4.260573 -4.457084 -2.563916 -1.388560  0.179481     2.0  \n",
       "4  4.420645 -3.035590 -1.190401 -0.421525 -0.883157     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (Use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s = StandardScaler()\n",
    "X_train_scale = s.fit_transform(X_train)\n",
    "\n",
    "p = PCA()\n",
    "X_train_pca = p.fit_transform(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evr = p.explained_variance_ratio_\n",
    "\n",
    "plt.plot(np.cumsum(evr), '-o')\n",
    "plt.bar(np.arange(np.size(evr)), evr, color='red')\n",
    "plt.ylabel('Explained Variance %')\n",
    "plt.xlabel('Components')\n",
    "plt.hlines(.95, 0, np.size(evr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the 12th component the total variance is 95%, which is what I would recommend using, as 95% is the general rule of thumb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Insert comments>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot.bar()\n",
    "plt.title('Distribution of Target Values', loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since the distribution is skewed, accuracy would be misleading. I would choose either recall or precision, depending on the use-case. Accuracy would skew towards the plurity class and recall would allow us to understand the ability for the model to recall the actual labels, which likely has a higher value then too many false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('glm',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rpi = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('glm', LogisticRegression(solver='liblinear'))]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'glm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'glm__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rpi = GridSearchCV(rpi, param_grid = params, scoring='recall_macro')\n",
    "rpi = rpi.fit(X_train, y_train)\n",
    "\n",
    "rpi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.14%\n",
      "Full training score: 72.73%\n",
      "Test score: 70.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {rpi.best_score_:.2%}')\n",
    "print(f'Full training score: {rpi.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {rpi.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.71      0.75       149\n",
      "         1.0       0.63      0.62      0.63        73\n",
      "         2.0       0.64      0.78      0.70        78\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.69      0.70      0.69       300\n",
      "weighted avg       0.72      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, rpi.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Best results so far on `C=0.1` using balanced classes. CV score was 72%, 73% on entire training data, and test 71%. Will search around `C=0.1` using balanced to target a better value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('glm',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpi = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('glm', LogisticRegression(solver='liblinear'))]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'glm__C': [0.3, 0.7, 0.9, 0.1, 0.25, 0.50, 0.80],\n",
    "    'glm__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rpi = GridSearchCV(rpi, param_grid = params, scoring='recall_macro')\n",
    "rpi = rpi.fit(X_train, y_train)\n",
    "\n",
    "rpi.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Refined search finds `C=0.1` as the \"best\", so we'll proceed with that as the non-PCA champion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('pca', PCA(n_components=14)),\n",
       "                ('glm',\n",
       "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pi = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('glm', LogisticRegression(solver='liblinear'))]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'pca__n_components': [8, 11, 12, 13, 14],\n",
    "    'glm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'glm__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pi = GridSearchCV(pi, param_grid = params, scoring='recall_macro')\n",
    "pi = pi.fit(X_train, y_train)\n",
    "\n",
    "pi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.14%\n",
      "Full training score: 72.73%\n",
      "Test score: 70.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {rpi.best_score_:.2%}')\n",
    "print(f'Full training score: {rpi.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {rpi.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Best model was regularization strength of 0.1, unweighted classes, and 13 principle components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.71      0.75       149\n",
      "         1.0       0.63      0.62      0.63        73\n",
      "         2.0       0.64      0.78      0.70        78\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.69      0.70      0.69       300\n",
      "weighted avg       0.72      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pi.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Test accuracy is 70% and precision and recall are about 68% each. CV accuracy is 72% and overall training is 73%, so no evidence of overfitting. Performance is nearly identical to the above logistic regression.\n",
    "\n",
    "> More targeted searches around 13 components and the `C=0.1` regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('pca', PCA(n_components=14)),\n",
       "                ('glm',\n",
       "                 LogisticRegression(C=0.06, class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('glm', LogisticRegression(solver='liblinear'))]\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'pca__n_components': [12, 13, 14, 15, 16],\n",
    "    'glm__C': [0.06, 0.08, 0.1, 0.25, 0.60, 0.80],\n",
    "    'glm__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pi = GridSearchCV(pi, param_grid = params, scoring='recall_macro')\n",
    "pi = pi.fit(X_train, y_train)\n",
    "\n",
    "pi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.14%\n",
      "Full training score: 72.73%\n",
      "Test score: 70.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {rpi.best_score_:.2%}')\n",
    "print(f'Full training score: {rpi.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {rpi.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.71      0.75       149\n",
      "         1.0       0.64      0.62      0.63        73\n",
      "         2.0       0.63      0.78      0.70        78\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.69      0.70      0.69       300\n",
      "weighted avg       0.72      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pi.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seeing no significant difference in the models using the more focused hyperparameters. Statistically irrelevant performance gain with slightly more regularization, but effectively the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.71      0.75       149\n",
      "         1.0       0.63      0.62      0.63        73\n",
      "         2.0       0.64      0.78      0.70        78\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.69      0.70      0.69       300\n",
      "weighted avg       0.72      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Regular Logistic Regression:')\n",
    "print(classification_report(y_test, rpi.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparing the PCA and non-PCA processing, the accuracies about about the same (71%), but the non-PCA logistic regression has slightly higher recall on the test data, so we'll prefer that model. In addition, it is also more interpretable in case we need to analyze the individual feature importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tr',\n",
       "                 DecisionTreeClassifier(class_weight='balanced', max_depth=8,\n",
       "                                        min_samples_split=0.02))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pine = Pipeline([\n",
    "    ('tr', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "pparams = {\n",
    "    'tr__max_depth': [4, 6, 8, 10, 12],\n",
    "    'tr__min_samples_split': [0.01, 0.02, 0.04, 0.06, 0.08],\n",
    "    'tr__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pine = GridSearchCV(pine, param_grid = pparams, scoring='recall_macro')\n",
    "pine = pine.fit(X_train, y_train)\n",
    "\n",
    "pine.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.89%\n",
      "Full training score: 87.42%\n",
      "Test score: 74.27%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {pine.best_score_:.2%}')\n",
    "print(f'Full training score: {pine.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {pine.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision trees have 73-74% accuracy on CV and test sets, however, the training has a 84% accuracy, so there is evidence of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.76      0.78       149\n",
      "         1.0       0.62      0.73      0.67        73\n",
      "         2.0       0.77      0.74      0.76        78\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.73      0.74      0.74       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pine.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall for the base tree is ~72% and precision is ~73%. Performing more targeted search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tr',\n",
       "                 DecisionTreeClassifier(class_weight='balanced', max_depth=8,\n",
       "                                        min_samples_split=0.02))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pine = Pipeline([\n",
    "    ('tr', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "pparams = {\n",
    "    'tr__max_depth': [4, 5, 6, 7, 8],\n",
    "    'tr__min_samples_split': [0.01, 0.02],\n",
    "    'tr__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pine = GridSearchCV(pine, param_grid = pparams, scoring='recall_macro')\n",
    "pine = pine.fit(X_train, y_train)\n",
    "\n",
    "pine.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 72.28%\n",
      "Full training score: 87.42%\n",
      "Test score: 73.82%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {pine.best_score_:.2%}')\n",
    "print(f'Full training score: {pine.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {pine.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly higher test accuracy using `max depth of 7`, however, the amount of overfitting increased, i.e., delta between training and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.74      0.77       149\n",
      "         1.0       0.61      0.73      0.66        73\n",
      "         2.0       0.77      0.74      0.76        78\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.73      0.74      0.73       300\n",
      "weighted avg       0.75      0.74      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pine.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on the test data is essentially the same between the base and refined decision tree models, so all else constant, we'd prefer the latter model, however, due to the overfitting and performance purity, we'd prefer the logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('pca', PCA(n_components=13)),\n",
       "                ('tr',\n",
       "                 DecisionTreeClassifier(class_weight='balanced', max_depth=6,\n",
       "                                        min_samples_split=0.01))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pine = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('tr', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "pparams = {\n",
    "    'pca__n_components': [4, 8, 11, 12, 13],\n",
    "    'tr__max_depth': [4, 6, 8, 10, 12],\n",
    "    'tr__min_samples_split': [0.01, 0.02, 0.04, 0.06, 0.08],\n",
    "    'tr__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pine = GridSearchCV(pine, param_grid = pparams, scoring='recall_macro')\n",
    "pine = pine.fit(X_train, y_train)\n",
    "\n",
    "pine.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Best model was 13 components, depth of 8, a minimum sample split of 2% of samples, and no class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.67%\n",
      "Full training score: 81.33%\n",
      "Test score: 69.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {pine.best_score_:.2%}')\n",
    "print(f'Full training score: {pine.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {pine.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There seems to be overfitting, i.e., 15 point accuracy drop-off between training and test. However, there is less overfitting, as expected, when using PCA than not using it, since we have a simpler feature set. The validation and test scores are lower as well, which again is not unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.79      0.78       149\n",
      "         1.0       0.64      0.68      0.66        73\n",
      "         2.0       0.81      0.74      0.77        78\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.74      0.74      0.74       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pine.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Accuracy was 68-69% of the test, with precision and recall at 65-68%.\n",
    "\n",
    "> Searching for more targeted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('pca', PCA(n_components=15)),\n",
       "                ('tr',\n",
       "                 DecisionTreeClassifier(max_depth=6, min_samples_split=0.02))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pine = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('tr', DecisionTreeClassifier())]\n",
    ")\n",
    "\n",
    "pparams = {\n",
    "    'pca__n_components': [11, 12, 13, 14, 15],\n",
    "    'tr__max_depth': [6, 7, 8, 9, 10],\n",
    "    'tr__min_samples_split': [0.01, 0.02, 0.03, 0.04],\n",
    "    'tr__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "pine = GridSearchCV(pine, param_grid = pparams)\n",
    "pine = pine.fit(X_train, y_train)\n",
    "\n",
    "pine.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined search comes up with `14 components`, a `max depth of 6` and `minimum samples of 2% in the splits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.67%\n",
      "Full training score: 81.33%\n",
      "Test score: 69.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {pine.best_score_:.2%}')\n",
    "print(f'Full training score: {pine.score(X_train, y_train):.2%}')\n",
    "print(f'Test score: {pine.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.75       149\n",
      "         1.0       0.61      0.63      0.62        73\n",
      "         2.0       0.68      0.62      0.64        78\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.68      0.67      0.67       300\n",
      "weighted avg       0.69      0.69      0.69       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pine.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More targeted search has minor performance gains versus the original search space, however, neither do as well as the logistic regression - about 2 points less in terms of accuracy while exhibiting overfitting. Within the logistic regressions, I'd prefer the non-PCA version, as we see no evidence of overfitting and the performance marks are about the same, and the underlying model will be more intrepretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda3e66817595a24f3b851fad3315f1c145"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
